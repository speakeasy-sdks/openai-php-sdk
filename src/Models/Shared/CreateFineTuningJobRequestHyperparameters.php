<?php

/**
 * Code generated by Speakeasy (https://speakeasyapi.dev). DO NOT EDIT.
 */

declare(strict_types=1);

namespace Openai\SDK\Models\Shared;


/**
 * CreateFineTuningJobRequestHyperparameters - The hyperparameters used for the fine-tuning job.
 * 
 * @package Openai\SDK\Models\Shared
 * @access public
 */
class CreateFineTuningJobRequestHyperparameters
{
    /**
     * Number of examples in each batch. A larger batch size means that model parameters
     * 
     * are updated less frequently, but with lower variance.
     * 
     * 
     * @var mixed $batchSize
     */
	#[\JMS\Serializer\Annotation\SerializedName('batch_size')]
    #[\JMS\Serializer\Annotation\Type('mixed')]
    #[\JMS\Serializer\Annotation\SkipWhenEmpty]
    public mixed $batchSize = null;
    
    /**
     * Scaling factor for the learning rate. A smaller learning rate may be useful to avoid
     * 
     * overfitting.
     * 
     * 
     * @var mixed $learningRateMultiplier
     */
	#[\JMS\Serializer\Annotation\SerializedName('learning_rate_multiplier')]
    #[\JMS\Serializer\Annotation\Type('mixed')]
    #[\JMS\Serializer\Annotation\SkipWhenEmpty]
    public mixed $learningRateMultiplier = null;
    
    /**
     * The number of epochs to train the model for. An epoch refers to one full cycle 
     * 
     * through the training dataset.
     * 
     * 
     * @var mixed $nEpochs
     */
	#[\JMS\Serializer\Annotation\SerializedName('n_epochs')]
    #[\JMS\Serializer\Annotation\Type('mixed')]
    #[\JMS\Serializer\Annotation\SkipWhenEmpty]
    public mixed $nEpochs = null;
    
	public function __construct()
	{
		$this->batchSize = null;
		$this->learningRateMultiplier = null;
		$this->nEpochs = null;
	}
}
