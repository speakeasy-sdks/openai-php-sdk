<?php

/**
 * Code generated by Speakeasy (https://speakeasyapi.dev). DO NOT EDIT.
 */

declare(strict_types=1);

namespace Openai\SDK\Models\Shared;


class CreateCompletionResponseChoices
{
    /**
     * The reason the model stopped generating tokens. This will be `stop` if the model hit a natural stop point or a provided stop sequence,
     * 
     * `length` if the maximum number of tokens specified in the request was reached,
     * or `content_filter` if content was omitted due to a flag from our content filters.
     * 
     * 
     * @var \Openai\SDK\Models\Shared\CreateCompletionResponseFinishReason $finishReason
     */
	#[\JMS\Serializer\Annotation\SerializedName('finish_reason')]
    #[\JMS\Serializer\Annotation\Type('enum<Openai\SDK\Models\Shared\CreateCompletionResponseFinishReason>')]
    public CreateCompletionResponseFinishReason $finishReason;
    
	#[\JMS\Serializer\Annotation\SerializedName('index')]
    #[\JMS\Serializer\Annotation\Type('int')]
    public int $index;
    
	#[\JMS\Serializer\Annotation\SerializedName('logprobs')]
    #[\JMS\Serializer\Annotation\Type('Openai\SDK\Models\Shared\Logprobs')]
    public Logprobs $logprobs;
    
	#[\JMS\Serializer\Annotation\SerializedName('text')]
    #[\JMS\Serializer\Annotation\Type('string')]
    public string $text;
    
	public function __construct()
	{
		$this->finishReason = \Openai\SDK\Models\Shared\CreateCompletionResponseFinishReason::Stop;
		$this->index = 0;
		$this->logprobs = new \Openai\SDK\Models\Shared\Logprobs();
		$this->text = "";
	}
}
