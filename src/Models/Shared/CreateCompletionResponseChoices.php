<?php

/**
 * Code generated by Speakeasy (https://speakeasyapi.dev). DO NOT EDIT.
 */

declare(strict_types=1);

namespace Openai\SDK\Models\Shared;


class CreateCompletionResponseChoices
{
    /**
     * The reason the model stopped generating tokens. This will be `stop` if the model hit a natural stop point or a provided stop sequence,
     * 
     * or `length` if the maximum number of tokens specified in the request was reached.
     * 
     * 
     * @var \Openai\SDK\Models\Shared\CreateCompletionResponseChoicesFinishReason $finishReason
     */
	#[\JMS\Serializer\Annotation\SerializedName('finish_reason')]
    #[\JMS\Serializer\Annotation\Type('enum<Openai\SDK\Models\Shared\CreateCompletionResponseChoicesFinishReason>')]
    public CreateCompletionResponseChoicesFinishReason $finishReason;
    
	#[\JMS\Serializer\Annotation\SerializedName('index')]
    #[\JMS\Serializer\Annotation\Type('int')]
    public int $index;
    
	#[\JMS\Serializer\Annotation\SerializedName('logprobs')]
    #[\JMS\Serializer\Annotation\Type('Openai\SDK\Models\Shared\CreateCompletionResponseChoicesLogprobs')]
    public CreateCompletionResponseChoicesLogprobs $logprobs;
    
	#[\JMS\Serializer\Annotation\SerializedName('text')]
    #[\JMS\Serializer\Annotation\Type('string')]
    public string $text;
    
	public function __construct()
	{
		$this->finishReason = \Openai\SDK\Models\Shared\CreateCompletionResponseChoicesFinishReason::Stop;
		$this->index = 0;
		$this->logprobs = new \Openai\SDK\Models\Shared\CreateCompletionResponseChoicesLogprobs();
		$this->text = "";
	}
}
